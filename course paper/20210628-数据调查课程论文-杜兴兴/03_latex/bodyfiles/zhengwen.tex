\chapter{绪论}
%---------------------------------------
\section{研究背景}
%---------------------------------------
研究表明，全球超过1/5的人正在遭受疼痛的折磨，其中半数患者的疼痛程度达到中度或重度水平，65 岁以上的老年人慢性疼痛的发生率更是超过50\%。 在疼痛折磨着人类的同时，也产生了各种各样的疼痛缓解药物。其中作为有效缓解中、重度疼痛的阿片类药物，虽然许多人需要阿片类药物来控制他们的慢性和严重的疼痛，但这些治疗的一个常见后果是滥用、成瘾和升级到更恶劣的药物[1]。阿片类药物是一种麻醉性止痛药，包括非法毒品海洛因，他们从罂粟花中提取，或人工合成，结构与其他阿片类药物相似[2]。 一些阿片类处方药的例子是吗啡、氢考酮、双氢吗啡酮和芬太尼。虽然这类药物中几乎每一种都可以用来治疗慢性疼痛，但阿片类药物的使用已经远远超出了处方药的范围，而且已经成为一种流行病[3]。

据统计，仅2013年全球就有2800万至3800万人非法使用阿片类药物（占15~65岁之间全球人口的0.6\%$\sim$0.8\%）。根据美国疾病控制和预防中心的数据显示，阿片类药物的滥用已经导致美国历史上最为严重的药物过量使用，并于2014 年将该问题列入五大公共卫生挑战之一[4]。 阿片类药物大体可以为三大类：非合成阿片类药物:可待因、吗啡、鸦片；半合成阿片类药物:氢可酮、羟可酮、丁丙诺啡、海洛因；合成阿片类药物:芬太尼、布托啡诺、美沙酮、丙氧芬。2013 年以来芬太尼等合成阿片类药物相关的死亡人数增加，其中2016 年芬太尼及相关药物死亡人数就超过2 万人。1999~2017 年统计数据显示，非法使用阿片类药物的群体中，男性比女性占有更大的人数比例，18~25 岁的年龄群体且更容易接触到阿片类药品[5]。

在过去几十年里，阿片类药物滥用不仅仅是美国存在的问题，包括中国、美国、欧洲在内的世界大部分国家和地区都存在该问题。因此，应对阿片类药物滥用是一个全球性的公共卫生问题。这种药物成瘾对社会的核心稳定发展构成了严重的威胁[6]。

机器学习包括有指导学习、无指导学习、半指导学习三种类别。有指导学习是指有结果度量的监督学习过程，例如根据病人的饮食习惯和血糖、血脂来预测糖尿病是否发作。通过学习已知数据集的特征和结果建立起预测模型来预测并度量未知数据的特征和结果。结果度量一般分为定量和定性两种，分别对应与统计学中的回归和分类问题。常见的有指导学习包括：决策树、神经网络、支持向量机、集成学习等。无指导学习是只能观察特征，没有结果度量，此时只能从总体中给出的样本信息对总体做出某些推断以及描述数据是如何组织或聚类的。并不需要某个结果度量或训练集，例如聚类分析、关联规则分析等。半指导学习是近年来机器学习中一个备受关注的内容，已得的观察量中一部分是经由指导者鉴定并加上标识的数据，称为已标识数据，另一部分观察量由于种种原因未能标识，称为未标识数据。通过利用已标识数据去分析并指出适当的一般性规律，再利用此规律去推断得出有关未标识数据的标识。但现在半指导学习方法的性能通常不太稳定，而且半指导学习技术在什么样的条件下能够有效地改善学习性能也不够明确。

%---------------------------------------
\section{研究现状}
%---------------------------------------
\vspace{-0.5em}

国内外研究表明，阿片类药物的滥用是一个多影响因素且影响因素见关系复杂的公共卫生事件。目前关于此类问题预测的方法主要以传统的logistic回归模型（logistic regression）为主。但传统模型在使用条件上较为苛刻，需要考虑数据分布是否合适、变量之间的共线性和交互作用等多种问题，特别是对多变量的问题尤为明显。因此，应用传统回归模型进行预测阿片类药物使用情况具有一定的局限性[7]。

机器学习作为人工智能领域的“内核”，通过研究历史数据抓取事务的本质特征，以模型或算法为代表的呈现方式，实现分类、预测、回归拟合等分析行为[8]。对于多重共线性问题，机器学习中的神经网络模型可以很好的解决，而且对于数据的分布几乎没有任何限制。对于变量属性间的交互作用，贝叶斯网络模型可以反应不同因素间的相互关系。在自变量属性众多（如，成百上千个），传统模型不稳定甚至根本无法建立模型，集成学习却可以解决，且模型稳健。而在传染病扩散、毒品传播、疾病预后等多变量、影响因素间相互作用负责的情况下，机器学习算法模型可能显著优于传统预测模型[9]。

目前在结合机器学习算法的研究中，韦可等人通过使用多项式回归的方法，借助支持向量机确定了多项式具体参数，预测了阿片类药物滥用率。他们所提出的模型虽然具有一定的普适性并能用于预测多个县的药物使用总量，但只是使用了机器学习中一种比较常见和普遍性比较高的算法，并不能比较除不同机器学习算法中的差异优劣[10]。

正是由于阿片类药物使用量的影响因素复杂、使用量差异较大。且自变量之间存在多重共线性和交互作用。传统的预测模型在预测这类问题时受限，为解决这个问题，本研究利用人工智能核心技术的多种机器学习算法来预测阿片类药物使用量。通过评价比较不同的机器学习算法来确定最佳的模型，以此来描述和预测分析阿片类药物使用量问题[11]。


目前广泛应用的机器学习算法包括神经网络、K近邻法、支持向量机、决策树、随机森林等，这些算法已经广泛应用与工程学、建筑学等领域，却很少有研究将这些算法应用在公共卫生领域，为了更好地评估这些算法是否能够有效地预测阿片类药物使用量以及寻找具有最好分类效果的分类算法。

本研究比较了6种算法的分类效能，通过多种机器学习算法预测阿片类药物使用量来评价和比较不同的机器学习算法，最终确定最佳的模型。

%---------------------------------------
\section{本文思路}
%---------------------------------------
对不同地区、不同类型的阿片类药物进行描述性分析。通过数据可视化来描述药物使用情况，包括阿片类药物使用的数量和地域趋势，通过可视化的描述得出初步猜测，以便后续深入的建模分析研究。

提取强相关性的社会、经济属性。由于所分析的与阿片类药物使用相关的各种社会经济属性太多，且考虑到过拟合问题和简化模型，因此不适合简单的将所有社会、经济因素加入模型中。通过计算所有变量在各个年份与阿片类药物的相关系数，将2010-2016年相关系数均大于0.5的变量纳入模型中。

将整理后的数据按照7:3的比例划分为训练集和测试集，通过机器学习算法建立模型，利用多种机器学习算法来预测阿片类药物使用量。将强相关性的社会、经济属性纳入到不同的机器学习算法中，具体包括如下算法：K-临近算法（K-Nearest Neighbor Algorithm）、支持向量机(Support Vector Machines)、决策树(Decision Tree)、神经网络（Neural Networks）、随机森林（Random Forest）、线性回归（Linear Regression）。

评价和比较不同算法的优劣。通过不用方法的机器学习模型的预测结果的错误率、F1评分、支持度、K 折训练集等性能指标评价和比较不同模型的优劣，以期进一步完善机器学习方法在阿片类药物使用量预测分析的统计学模型。




\chapter{方法与数据}
%---------------------------------------
\section{分析说明}
%---------------------------------------
采用Office Excel2016整理数据，通过Python3.6软件对数据进行进一步分析，使用到的程序包有os、zipfile、numpy、pandas、seaborn、matplotlib、sklearn。 主要使用到的统计分析方法有数据可视化、K 近邻算法、决策树算法、支持向量机算法、随机森林算法、神经网络算法、逻辑回归算法。
%---------------------------------------
\section{方法说明}
%---------------------------------------
\subsection{K最近邻法}
%---------------------------------------
K最近邻法（KNN，K-Nearest Neighbor）是数据挖掘分类技术中最简单的方法之一，非常容易理解应用[17]。根据距离函数计算待分类样本x和每个训练样本的距离，选择与待分类样本距离最小的K个样本作为x的K个最近邻，最后根据x的K个最近邻判断x的类别。通常K是不大于20的整数。依赖于训练数据集和K的取值，输出结果可能会有不同，所以需要评估算法的正确率，选取产生最小误差率的K[18]。而关于距离的度量方法常用的主要有以下几种：

	欧氏距离：
\begin{equation}
dist(X,Y)=\sqrt{\sum_{i=1}^{n}(x_i-y_i)^2}
\label{s}
\end{equation}%
	明式距离：
\begin{equation}
dist(X,Y)=(\sum_{i=1}^{n}|x_i-y_i|^p)^{\frac{1}{p}}
\label{s}
\end{equation}%
	曼哈顿距离：
\begin{equation}
dist(X,Y)=\sum_{i=1}^{n}|x_i-y_i|
\label{s}
\end{equation}%

曼哈顿距离来源于城市区块距离，是将多个维度上的距离进行求和后的结果，即当明式距离公式中p=1时得到的距离度量公式即为曼哈顿距离。

	切比雪夫距离：

\begin{equation}
dist(X,Y)=\lim_{n\to \infty}(\sum_{i=1}^n|x_i-y_i|^p)^{\frac{1}{p}}=max|x_i-y_i|
\label{s}
\end{equation}%

KNN进行分类预测的具体步骤如下[19]：

	1) 计算测试数据与各个训练数据之间的距离；

	2) 按照距离的递增关系进行排序；

	3) 选取距离最小的K个点；

	4) 确定前K个点所在类别的出现频率；

    5) 返回前K个点中出现频率最高的类别作为测试数据的预测分类。

本文使用的是sklearn包中的KNeighborsClassifier方法实现K最近邻算法分类，对三种阿片类药物报告量预测做KNN 分类。
%---------------------------------------
\subsection{决策树}
%---------------------------------------
一般而言，一颗决策树包含一个根节点、若干个内部节点、若干个叶子节点；叶子节点对应决策结果，其他每个节点对应一个属性测试，每个节点包含的样本集合根据属性测试的结果被划分到子节点中；根节点包含样本全集，从根节点到每个叶子节点的路径对应了一个判定测试序列。决策树算法处理过拟合的主要手段便是通过剪枝，基本策略包括预剪枝和后剪枝。剪枝处理降低了过拟合风险，但也带来了欠拟合的风险。一般情况下后剪枝决策树欠拟合风险较小，泛化能力性能往往优于预剪枝决策树。但后剪枝训练开销比未剪枝和预剪枝决策树都要大很多。

决策树进行分类预测的具体步骤如下：

1) 对数据源进行数据预处理，得到训练集和测试集；

2) 对训练集进行训练；

3) 对初始决策树进行剪枝；

4) 由所得到的决策树提取分类规则；

5) 使用测试数据集进行预测，评估决策树模型。

本文使用的是sklearn包中的DecisionTreeClassifier方法实现决策树分类，对三种阿片类药物报告量预测建立决策树模型。
%---------------------------------------
\subsection{随机森林}
%---------------------------------------
随机森林（RF，Random Forest）是一种组成式的有监督学习方法。由多颗决策树构成，且森林中的每一颗决策树之间没有关联，模型的最终输出由森林中的每一颗决策树共同决定。随机森林的随机性主要体现在两个方面：样本的随机性，从训练集中随机抽取一定数量的样本，作为每颗决策树的根节点样本；属性的随机性，在建立每颗决策树时，随机抽取一定数量的候选属性，从中选择最合适的属性作为分裂节点[21]。

随机森林进行预测的步骤如下：

1) 从训练集中随机抽取一定数量的样本，作为每棵树的根节点样本；

2) 在建立决策树时，随机抽取一定数量的候选属性，从中选择最合适属性作为分裂节点；

3) 建立好随机森林以后，对于测试样本，进入每一颗决策树进行类型输出或回归输出；每一颗决策树输出的均值作为最终结果。

在Python中本文使用的是sklearn包中的RandomForestClassifier方法实现随机森林分类，对不同类的阿片类药物报告量预测做随机森林分类模型。
%---------------------------------------
\subsection{支持向量机}
%---------------------------------------
支持向量机（SVM，Support Vector Machine）是一种监督学习算法，可用于分类和回归问题。主要目标是找到最佳超平面，以便在不同类的数据点之间进行正确的分类。支持向量机中有许多不同类型的内核可用于创建这种更高维的空间，例如线性，多项式，Sigmoid和径向基函数。在分类问题中，还可以应用一种被广泛应用的模型―支持向量机，这种算法在学习复杂的非线性方程时通过一种内核函数的映射为线性方程的方式。

支持向量机的主要优势有如下几点：在高维空间的情况下支持向量机算法处理任然有效；如果维度高于采样数量的情况一下依然有效；在决策函数中可以使用训练点的子集；可以为决策函数指定不同的核函数。支持向量机主要有以下缺点：如果特征的数量大大多于采样的数量，为了避免过拟合，合理的正则化变得至关重要；除此之外支持向量机算法并不能直接提供概率估计结果[23]。

在Python中本文使用的是sklearn包中的SVM 方法实现支持向量机分类，对不同类的阿片类药物报告量预测做支持向量机模型分类。
%---------------------------------------
\subsection{神经网络}
%---------------------------------------
人工神经网络（ANNs，Artificial Neural Networks）起源于1940-1950年，使通过模仿生物神经的行为特征，形成一种具有学习、联想、记忆和模式识别的人工系统，称为人工神经网络。这种网络依靠系统的复杂度，通过调整内部大量节点之间相互连接的关系，从而达到信息处理的目的[24]。
人工神经网络具有自学习和自适应的能力，可以通过预先提供的一批相互对应的输入输出数据，分析两者的内在关系和规律，最终通过这些规律形成一个复杂的非线性系统函数，这种学习分析过程被称作“训练”。神经元的每一个输入连接都有突触连接强度，用一个连接权值来表示，即将产生的信号通过连接强度放大，每一个输入量都对应有一个相关联的权重[25]。激活函数具有如下性质：可微性，非线性、单调性、输出值于输入值相差不会很大。

在Python中本文使用的是sklearn包中的MLPClassifier方法实现支持人工神经网络分类，对不同类的阿片类药物报告量预测做人工神经网络模型分类。
%---------------------------------------
\subsection{Logistic回归}
%---------------------------------------
Logistic回归（LR，Logistic Regression）属于概率型的非线性回归，对于二分类的Logistic回归，因变量y只有“是、否”两个取值，记为$1$和$0$。考虑具有n个独立变量的向量$x=(x_1,x_2,...,x_n)$，设条件概率$P(y=1|x)=p$为根据观测量相对于某事件x 发生的概率[9]。那么Logistic回归模型可以表示为：

\begin{equation}
P(y=1|x)=\frac{1}{1+e^{-g(x)}}
\label{s}
\end{equation}%

这里的$f(x)=\frac{1}{1+e^{-x}}$称为Logistic函数，其中$g(x)=\beta_0+\beta_1 x_1+...+\beta_n x_n$。 那么在x的条件下y不发生的概率为：
\begin{equation}
P(y=0|x)=1-P(y=1|x)=1-\frac{1}{(1+e^{-g(x)})}=\frac{1}{1+e^{-g(x)}}
\label{s}
\end{equation}%
所以事件发生与不发生的概率之比为：
\begin{equation}
\frac{P(y=1|x)}{P(y=0|x}=\frac{p}{1-p}=e^{g(x)}
\label{s}
\end{equation}%
这个比值称为事件的优势比，简记为odds。对odds取对数得到：
\begin{equation}
ln(\frac{p}{1-p})=g(x)=\beta_0+\beta_1 x_1+...+\beta_n x_n
\label{s}
\end{equation}%
可以看出Logistic回归都是围绕Logistic函数来展开的。通过极大似然估计求解模型的参数。假设有m个观测样本，观测值分别为$y_1,y_2,...,y_n$，设$p_i=P(y=1|x_i)$为给定条件下得到$y_i=1$的概率，同样地，$y_i=0$的概率为$P(y_i=0|x_i)=1-p_i$，所以得到一个观测值的概率为：
\begin{equation}
P(y_i )=p_i^{y_i}(1-p_i)^{1-y_i}
\label{s}
\end{equation}%
因为各个观测样本之间相互独立，那么他们的联合分布等于各边缘分布的乘积，得到似然函数为：
\begin{equation}
L(\beta)=\prod_{i=1}^{m}(p(x_i))^{y_i}(1-p(x_i))^{1-y_i}
\label{s}
\end{equation}%
取对数得：
\begin{equation}
lnL(\beta)=\sum_{i=1}^{m} { y_i ln[p(x_i)]+(1-y_i)ln[1-p(x_i)]},  \label{s}
\end{equation}%
对这$n+1$个$\beta_i$分布求偏导，得到$n+1$个方程：
\begin{equation}
\frac{\partial{ln(L(\beta_k))}}{\partial{\beta_k}}=\sum_{i=1}^{m}x_{ik}[y_i-p(x_i)]=0
\label{s}
\end{equation}%
这样的$n+1$个方程的解即为模型的参数估计。如同所有的回归模型一样，Logisitic 回归的主要兴趣是在于参数估计值、估计标准误、t比率以及统计显著程度。这些信息构成了所有估计广义线性模型的统计分析的核心结果。因为Logistic的参数较其它模型的参数更易于解释，对二元因变量，它是最广泛被应用的模型。

在Python中本文使用的是sklearn包中的LogisticClassifier方法实现支持逻辑回归分类，对不同类的阿片类药物报告量预测做逻辑回归模型分类。

%---------------------------------------

\section{评估方法}
%---------------------------------------
\subsection{精准率}
%---------------------------------------
精准率（Precision）又叫查准率，对于给定测试集的某一类别，分类模型预测正确的比例（混淆矩阵的列维）。主要是针对预测结果而言，在预测为正样本的结果中，我们有多少把握可以预测正确。
\begin{equation}
Precision=\frac{TP}{TP+FP},  \label{s}
\end{equation}%

%---------------------------------------
\subsection{召回率}
%---------------------------------------
召回率（Recall）又叫查全率，它是针对原样本而言的，在真实值是正例的所有结果中，模型预测正确的比例。召回率越高，代表实际负样本被预测出来的概率越高。
\begin{equation}
Recall=\frac{TP}{TP+FN},  \label{s}
\end{equation}%

%---------------------------------------
\subsection{F1评分}
%---------------------------------------
由于精确率与召回率通常是此消彼长的，很难兼得，在大规模数据集合中相互制约。而F1 评分是最常见去同时考虑这两个指标。当$a=1$ 时，$ （F=\frac{2Precision*Recall}{2(Precision+Recall)}）$便是权重因子，代表精确率和召回率的权重相同。
\begin{equation}
F1_{score}=\frac{(a^2+1)*Precision*Recall}{a^2*(Precision+Recall)},  \label{s}
\end{equation}%

%---------------------------------------
\subsection{支持度}
%---------------------------------------
支持度（Support）表示同时包含A和B事务占所有事务的比例。也就是规则前后同时在数据集中出现的比率。
\begin{equation}
Support=P(A\&B),  \label{s}
\end{equation}%
%---------------------------------------
\subsection{K折交叉验证}
%---------------------------------------
K折交叉验证（K-fold cross-validation），将训练集分割为K个样本，随机选择其中k-1 个样本作为训练集来训练模型，将剩余的1 个样本作为测试集来验证模型的效果。将这个过程重复k 次，每个子样本验证一次，将k 次的结果通过平均的方式综合为一个单一指标进行评估。其中当$k=10$时较为常用，称为10次交叉验证。

在python中本文使用的是sklearn包中的model\_selection 方法实现k 折交叉验证，对本文所使用得模型进行10折交叉验证各个模型的优劣。
%---------------------------------------
\section{数据说明}
%---------------------------------------
数据来源于美国国家法医实验室信息系统（https://www.nflis.deadiversion.usdoj.gov）与美国人口统计局（https://www.commerce.gov）。数据包括美国7 年(2010-2016年)462 个县的共计24062 条阿片类药物鉴定计数，以及各年份各县的704 个一系类常见的社会经济因素。这462个县主要来自于这五个州：俄亥俄州、肯塔基州、西弗吉尼亚州、弗吉尼亚州和宾夕法尼亚州。
%---------------------------------------
\section{数据处理}
%---------------------------------------
收集到的原始数据包括2010年-2016年共24062条观测数据。其中在2010年、2011 年、2012 年均为600 个特征变量；在2013年为612 个特征变量；2014 年、2015年、2016 年均为612 个特征变量。由于数据的复杂性已经部分数据存在缺失等情况，且不同年份的特征变量可能存在不同，不便于直接对数据进行统计分析，因此分析前对数据进行了一定的整理，具体如下：
%---------------------------------------
\subsection{无效数据处理}
%---------------------------------------
删除只在特定年份测量的因素，因为多年的趋势将较少出现，更容易受到潜在的异常值影响；删除所有县数据不完整的因素，由于可能存在由于数据缺失而不明显的隐藏趋势而使模型的效果产生一定程度的误差。 处理之后还剩19646条观测数据，704 个特征变量。
%---------------------------------------
\subsection{缺失值处理}
%---------------------------------------
收集到得数据某些字段值为空得情况很多，一般有三种处理方法：删除记录、数据填补、空值处理。填补缺失值方法有：人工填补、均数填补、中位数或众数填补、多重填补、使用最接近的样本值填补等。不同情况变量的缺失值本研究采用了不同的处理方式[14]。 当某一条观测数据缺失项大于总项的65\%时，由于缺失信息较大，故选择删除记录；考虑到不偏离原数据的总体分布，故在删除记录之后用列均值对缺失数据进行填补。处理之后还剩9395 条观测数据，704个特征变量。
%---------------------------------------
\subsection{离散化处理}
%---------------------------------------
连续性变量的离散化就是将连续属性的值域划分成为若干个离散的区间，最后用不同的数值或者符合代表观测值落在每个区间的属性值[13]。连续变量的离散化的目的是减少给定的定性变量的属性值得个数。在模型解释方面，离散化数据更容易解读，且消除了某些异常值的影响起到一定作用。本次实证研究将各县的阿片类药物使用报告量离散化成6个水平：0例、1-9例、10-99例、100-499例、500-999例、1000-4999例、5000例以上[14]。
%---------------------------------------
\subsection{变量选取处理}
%---------------------------------------
冗余是数据集成的一个重要问题，冗余属性出现的情况可能为同一属性因为变量名不同，出现多次导致重复。通过使用相关性分析进行检测，检测出一个变量影响另一个变量的强度。

除此之外，由于社会经济属性较多，所以选择与应变量有较强的关联性的变量有助于模型的可解释性和精简性。因此通过计算各个自变量与应变量的相关系数来选择强相关属性。考虑到模型的广泛性，选择了2010年-2016年各个年份的社会经济属性与阿片类药物报告量的相关系数均大于0.5的所有变量，共有38个变量入选。

%---------------------------------------
\subsection{归一化处理}
%---------------------------------------
不同的变量有不同的量纲，比如人口、家庭户数、收入等，数值间的差别比较大，归一化就是为了消除变量之间量纲的影响，对原始数据进行标准化、归一化、中心化处理。标准化或归一化实质是一种线性变换，线性变换有很多良好的性质，这些性质决定了对数据改变处理后不会造成失效，反而提高数据的表现，这些性质是归一化或者标准化的前提[15]。

归一化就是将数据映射到某一固定区间，一般为（0,1）或（-1,1）。主要是为了数据处理方便提出来的，把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权，归一化处理过程仅由变量的极值决定[16]。

归一化公式：
\begin{equation}
x^*=\frac{x - x_{min}}{x_{max}-x_{min}},  \label{s}
\end{equation}%
标准化会使每个特征中的数据平均值变为0、标准差变为1，标准化是依照特征矩阵的列处理数据，通过就z-score的方法转换为标准正态分布。

标准化公式：
\begin{equation}
x^*=\frac{x - x_{arg}}{\sigma},  \label{s}
\end{equation}%
中心化便是数据的平均值变换为0，而标准差无确切要求。

中心化公式：
\begin{equation}
x^*=x - x_{arg},  \label{s}
\end{equation}%

考虑到量纲不同问题，故本文对除结局变量外的所有变量均用归一化方法进行处理。处理之后共计还剩9395条有效观测数据，38个特征变量。
%---------------------------------------
\subsection{数据集划分处理}
%---------------------------------------
按照合成类阿片药、非合成类阿片药、半合成阿片药分层（具体药物类别划分方式见3.1.2 节），将上述处理之后数据按照7:3 的比例划分为训练集和测试集。得到合成类阿片药的训练集共2242条观测，测试集共961条观测；非合成类阿片药的训练集共2092 条观测，测试集共897条观测；半合成类阿片药的训练集共2242 条观测，测试集共961 条观测。
%---------------------------------------



\chapter{结果}
%---------------------------------------
\section{数据描述}
%---------------------------------------
\subsection{现状分析}
%---------------------------------------
\label{st1}
(1) 总体阿片类药物的使用情况。为了观察总体数据的分布情况，通过对所有数据的描述性分析得到图3.1和 图3.2。从图中可以看出，报告的阿片类药物共有56 种，各类阿片类的分布主要集中在海洛因、氢考酮、氢可酮这三类，分别占比为53.24\%、19.79\%、8.57\%，海洛因的报告量达到25000 多例，氢考酮的报告量为10000 多例，氢可酮的报告量为4000多例；大部分类型的阿片类药物都小于0.01\%；而较为常见的可卡因、吗啡等占比并没有想象中的那么高，比例分别为0.73\%、1.88\%。
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.85\textwidth]{bodyfigures/Figure1_Pie.jpg}
\end{center}
\caption{各类阿片类药物报告比例饼图}
\label{q1}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.85\textwidth]{bodyfigures/Figure2_Bar.jpg}
\end{center}
\caption{各类阿片类药物报告量分布直方图}
\label{q2}
\end{figure}

 (2) 不同地区阿片类药物的使用情况。在得到总体药物使用的分布情况后，进一步分析不同地区的药物使用情况。根据2010-2016 年不同州的不同种类报告量绘制了热力图，见图3.3。可以发现，虽然不同年份的报告量有一定的差异，但是在类别上展出来的差异更加明显，肯塔基州主要为氢考酮、海洛因、氢可酮阿片药，俄亥俄州主要为海洛因、氢考酮、丁丙诺啡阿片药，宾夕法尼亚州主要为海洛因、氢考酮、丁丙诺啡阿片药，弗吉尼亚州主要为氢可酮、氢考酮、海洛因阿片药，西弗吉尼亚州主要为氢考酮、氢可酮、海洛因阿片药；可以从图上发现图形模式大致呈现3个板块，第一个板块主要以海洛因阿片药为主；第二板块主要以氢考酮为主，第三板块主要以丁丙诺啡为主。基于这三大板块类别便可以将原本56种阿片类药物重新划分为三大类。
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.95\textwidth]{bodyfigures/Figure3_HeatMap.jpg}
\end{center}
\caption{各个州各种阿片类药物报告量的热力图}
\label{q3}
\end{figure}

%---------------------------------------
\subsection{药物种类划分}
%---------------------------------------
\label{st1}
根据阿片类药物是否为合成药物将其划分为三大类：合成类阿片药、非合成类阿片药、半合成类阿片药。基于其报告量（见表 3.1）对2010-2016年各个州的报告量绘制折线图。

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[H]
  \centering
  \caption{2010-2016年五大州的3类阿片类药物报告量}
    \begin{tabular}{lcccccc}
    \toprule
    \textbf{药物种类} & \textbf{年份} & \textbf{肯塔基州} & \textbf{俄亥俄州} & \textbf{宾夕法尼亚州} & \textbf{弗吉尼亚州} & \textbf{弗吉尼亚州} \\
    \midrule
    半合成阿片类药物 & 2010年 & 3952  & 12153 & 14450 & 4381  & 1535 \\
          & 2011年 & 4068  & 13775 & 14100 & 3092  & 1473 \\
          & 2012年 & 5132  & 17244 & 15019 & 3862  & 1689 \\
          & 2013年 & 6809  & 21238 & 16437 & 7062  & 2444 \\
          & 2014年 & 7151  & 23914 & 20493 & 5460  & 1942 \\
          & 2015年 & 6383  & 26674 & 20799 & 5842  & 1535 \\
          & 2016年 & 5829  & 24561 & 19155 & 6271  & 1528 \\
    \midrule
    合成阿片类药物 &       &       &       &       &       &  \\
          & 2010年 & 6208  & 6928  & 4689  & 3811  & 1249 \\
          & 2011年 & 5917  & 5999  & 5207  & 3189  & 1672 \\
          & 2012年 & 5224  & 5284  & 4383  & 3390  & 1521 \\
          & 2013年 & 3961  & 5060  & 3537  & 4004  & 1500 \\
          & 2014年 & 3628  & 6391  & 4030  & 3140  & 1251 \\
          & 2015年 & 3266  & 9843  & 4474  & 2613  & 994 \\
          & 2016年 & 3089  & 17347 & 6654  & 3596  & 988 \\
    \midrule
    非合成阿片类药物 &       &       &       &       &       &  \\
          & 2010年 & 293   & 626   & 675   & 493   & 106 \\
          & 2011年 & 299   & 551   & 680   & 466   & 126 \\
          & 2012年 & 366   & 615   & 557   & 579   & 166 \\
          & 2013年 & 378   & 547   & 435   & 609   & 102 \\
          & 2014年 & 302   & 555   & 381   & 437   & 87 \\
          & 2015年 & 216   & 610   & 378   & 355   & 42 \\
          & 2016年 & 175   & 562   & 355   & 328   & 31 \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

从图3.4可以看出不同州的不同类的阿片药报告量在2010-2016年呈现不同趋势，肯塔基州合成阿片药在2010年报告量为峰值6208 例，半合成类阿片药在2014年达到峰值7151 例；俄亥俄州半合成阿片药在2015年达到峰值26674 例，而合成阿片药报告量在2013年最低为5060例，2016年最高为17347 例；宾夕法尼亚州的半合成阿片药的报告量大致也呈现一个先增后减的趋势，在2015 年达到峰值20799例；弗吉尼亚州的半合成阿片药在2011 年和2013 年分别出现一个波谷和波峰；西弗吉尼亚州的半合成阿片药在2013年出现一个波峰，合成类阿片药在整体上呈现一个递减趋势；非合成阿片药变化趋势不明显；而这五个州的总体上而言，半合成阿片类药物呈现一个先增后减的趋势，而合成类阿片药为先减后增的趋势，非合成类阿片药变化趋势相对不明显。

\begin{figure}[H]
\begin{center}
\includegraphics[width=0.85\textwidth]{bodyfigures/Figure4_Plot.jpg}
\end{center}
\caption{2010-2016年五大州的3类阿片类药物报告量折线图}
\label{q4}
\end{figure}

可以发现，五个州阿片药物使用量趋势近似相同，合成类阿片类药物的变化趋势与半合成类阿片类药物的变化趋势相反，非合成类阿片药变化趋势不大。

由探索性分析可知，五个州在不同的阿片类药物有着近似相同的变化趋势，半合成阿片类药物呈现一个先增后减的趋势，而合成类阿片药为先减后增的趋势，非合成类阿片药变化趋势相对不明显。因此，为了简化模型和提升模型的泛化能力，将本研究所使用到的机器学习模型应用到测试集的不同类别阿片类药物报告量预测，具体的各个影响因素详见附录B，通过不同模型的预测结果评估模型优劣。


%---------------------------------------
\section{应用模型}
%---------------------------------------
\label{st2}
将K近邻模型、决策树、随机森林、支持向量机、神经网络、Logistic 回归6种模型应用于合成类阿片药，得到表 3.2 所示的混淆矩阵。
% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table}[H]
  \centering
  \caption{6种模型预测合成阿片类药物的混淆矩阵}
    \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{clcccccc}
    \toprule
    \multirow{2}[3]{*}{\textbf{模型方法}} & \multicolumn{1}{c}{\multirow{2}[3]{*}{\textbf{测试集实际分类}}} & \multicolumn{6}{c}{\textbf{预测结果}} \\
\cmidrule{3-8}          &       & \textbf{0人} & \textbf{1-9 人} & \textbf{10-99人} & \textbf{100-499 人} & \textbf{500-999 人} & \textbf{1000-4999人} \\
    \midrule
    K近邻法  &       &       &       &       &       &       &  \\
          & 0人    & 31    & 51    & 15    & 4     & 0     & 0 \\
          & 1-9人  & 44    & 150   & 103   & 4     & 0     & 0 \\
          & 10-99人 & 12    & 84    & 354   & 24    & 0     & 0 \\
          & 100-499人 & 0     & 5     & 40    & 37    & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 1     & 1     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 1     & 0     & 0 \\
    \midrule
    决策树   &       & \multicolumn{6}{c}{} \\
          & 0人    & 40    & 46    & 13    & 2     & 0     & 0 \\
          & 1-9人  & 49    & 140   & 106   & 6     & 0     & 0 \\
          & 10-99人 & 24    & 99    & 311   & 40    & 0     & 0 \\
          & 100-499人 & 3     & 3     & 31    & 42    & 3     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 2     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 1     & 0 \\
    \midrule
    随机森林  &       & \multicolumn{6}{r}{} \\
          & 0人    & 35    & 43    & 23    & 0     & 0     & 0 \\
          & 1-9人  & 32    & 180   & 88    & 1     & 0     & 0 \\
          & 10-99人 & 5     & 95    & 367   & 7     & 0     & 0 \\
          & 100-499人 & 0     & 3     & 38    & 39    & 2     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 2     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 1     & 0 \\
    \midrule
    支持向量机 &       & \multicolumn{6}{c}{} \\
          & 0人    & 0     & 73    & 27    & 1     & 0     & 0 \\
          & 1-9人  & 0     & 178   & 123   & 0     & 0     & 0 \\
          & 10-99人 & 0     & 80    & 388   & 6     & 0     & 0 \\
          & 100-499人 & 0     & 2     & 60    & 20    & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 1     & 1     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 1     & 0     & 0 \\
    \midrule
    神经网络  &       & \multicolumn{6}{r}{} \\
          & 0人    & 22    & 52    & 23    & 4     & 0     & 0 \\
          & 1-9人  & 22    & 160   & 115   & 4     & 0     & 0 \\
          & 10-99人 & 2     & 71    & 379   & 22    & 0     & 0 \\
          & 100-499人 & 0     & 1     & 43    & 38    & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 2     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 1     & 0     & 0 \\
    \midrule
    Logistic回归 &       & \multicolumn{6}{c}{} \\
          & 0人    & 0     & 65    & 35    & 1     & 0     & 0 \\
          & 1-9人  & 1     & 173   & 126   & 1     & 0     & 0 \\
          & 10-99人 & 0     & 68    & 398   & 8     & 0     & 0 \\
          & 100-499人 & 0     & 1     & 57    & 24    & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 2     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 1     & 0     & 0 \\
    \bottomrule
    \end{tabular}
    }%
  \label{tab:addlabel}%
\end{table}%

将K近邻模型、决策树、随机森林、支持向量机、神经网络、Logistic 回归6种模型应用于半合成类阿片药，得到表 3.3所示的混淆矩阵。
% Table generated by Excel2LaTeX from sheet 'Sheet3'
\begin{table}[H]
  \centering
  \caption{6种模型预测半合成阿片类药物的混淆矩阵}
  \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{clcccccc}
    \toprule
    \multirow{2}[3]{*}{\textbf{模型方法}} & \multicolumn{1}{c}{\multirow{2}[3]{*}{\textbf{实际}}} & \multicolumn{6}{c}{\textbf{预测}} \\
\cmidrule{3-8}          &       & \textbf{0人} & \textbf{1-9 人} & \textbf{10-99人} & \textbf{100-499 人} & \textbf{500-999 人} & \textbf{1000-4999人} \\
    \midrule
    K近邻法  &       &       &       &       &       &       &  \\
          & 0人    & 22    & 38    & 13    & 1     & 0     & 0 \\
          & 1-9人  & 23    & 127   & 91    & 4     & 0     & 0 \\
          & 10-99人 & 9     & 71    & 331   & 39    & 0     & 0 \\
          & 100-499人 & 1     & 5     & 55    & 91    & 4     & 0 \\
          & 500-999人 & 0     & 0     & 1     & 14    & 5     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 4     & 3     & 9 \\
    \midrule
    决策树   &       & \multicolumn{6}{c}{} \\
          & 0人    & 20    & 34    & 18    & 2     & 0     & 0 \\
          & 1-9人  & 29    & 128   & 84    & 4     & 0     & 0 \\
          & 10-99人 & 14    & 93    & 299   & 43    & 1     & 0 \\
          & 100-499人 & 5     & 5     & 44    & 97    & 5     & 0 \\
          & 500-999人 & 0     & 0     & 2     & 7     & 11    & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 1     & 2     & 13 \\
    \midrule
    随机森林  &       & \multicolumn{6}{r}{} \\
          & 0人    & 23    & 38    & 10    & 3     & 0     & 0 \\
          & 1-9人  & 24    & 139   & 80    & 2     & 0     & 0 \\
          & 10-99人 & 7     & 85    & 328   & 30    & 0     & 0 \\
          & 100-499人 & 1     & 3     & 55    & 93    & 4     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 14    & 4     & 2 \\
          & 1000-4999人 & 0     & 0     & 1     & 1     & 2     & 12 \\
    \midrule
    支持向量机 &       & \multicolumn{6}{c}{} \\
          & 0人    & 0     & 57    & 14    & 3     & 0     & 0 \\
          & 1-9人  & 0     & 150   & 92    & 3     & 0     & 0 \\
          & 10-99人 & 0     & 77    & 339   & 34    & 0     & 0 \\
          & 100-499人 & 0     & 1     & 74    & 80    & 1     & 0 \\
          & 500-999人 & 0     & 0     & 1     & 17    & 1     & 1 \\
          & 1000-4999人 & 0     & 0     & 0     & 4     & 1     & 11 \\
    \midrule
    神经网络  &       & \multicolumn{6}{r}{} \\
          & 0人    & 0     & 56    & 16    & 2     & 0     & 0 \\
          & 1-9人  & 1     & 143   & 98    & 3     & 0     & 0 \\
          & 10-99人 & 4     & 81    & 319   & 45    & 0     & 1 \\
          & 100-499人 & 1     & 1     & 59    & 95    & 0     & 0 \\
          & 500-999人 & 1     & 0     & 0     & 15    & 0     & 4 \\
          & 1000-4999人 & 0     & 0     & 0     & 6     & 0     & 10 \\
    \midrule
    Logistic回归 &       & \multicolumn{6}{c}{} \\
          & 0人    & 0     & 46    & 26    & 2     & 0     & 0 \\
          & 1-9人  & 0     & 90    & 153   & 2     & 0     & 0 \\
          & 10-99人 & 0     & 32    & 389   & 29    & 0     & 0 \\
          & 100-499人 & 0     & 1     & 87    & 67    & 1     & 0 \\
          & 500-999人 & 0     & 0     & 1     & 18    & 0     & 1 \\
          & 1000-4999人 & 0     & 0     & 0     & 4     & 0     & 12 \\
    \bottomrule
    \end{tabular}
    }%
  \label{tab:addlabel}%
\end{table}%
将K近邻模型、决策树、随机森林、支持向量机、神经网络、Logistic 回归6种模型应用于半合成类阿片药，得到表 3.4所示的混淆矩阵。
% Table generated by Excel2LaTeX from sheet 'Sheet4'

\begin{table}[H]
  \centering
  \caption{6种模型预测半合成阿片类药物的混淆矩阵}
  \resizebox{0.75\textwidth}{!}{
    \begin{tabular}{clcccccc}
    \toprule
    \multirow{2}[3]{*}{\textbf{模型方法}} & \multicolumn{1}{c}{\multirow{2}[3]{*}{\textbf{实际}}} & \multicolumn{6}{c}{\textbf{预测}} \\
\cmidrule{3-8}          &       & \textbf{0人} & \textbf{1-9 人} & \textbf{10-99人} & \textbf{100-499 人} & \textbf{500-999 人} & \textbf{1000-4999人} \\
    \midrule
    K近邻法  &       &       &       &       &       &       &  \\
          & 0人    & 132   & 149   & 6     & 0     & 0     & 0 \\
          & 1-9人  & 112   & 376   & 19    & 0     & 0     & 0 \\
          & 10-99人 & 7     & 54    & 40    & 0     & 0     & 0 \\
          & 100-499人 & 0     & 0     & 2     & 0     & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
    \midrule
    决策树   &       & \multicolumn{6}{c}{} \\
          & 0人    & 138   & 131   & 18    & 0     & 0     & 0 \\
          & 1-9人  & 150   & 301   & 56    & 0     & 0     & 0 \\
          & 10-99人 & 13    & 37    & 49    & 2     & 0     & 0 \\
          & 100-499人 & 0     & 0     & 0     & 2     & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
    \midrule
    随机森林  &       & \multicolumn{6}{r}{} \\
          & 0人    & 157   & 126   & 4     & 0     & 0     & 0 \\
          & 1-9人  & 132   & 366   & 9     & 0     & 0     & 0 \\
          & 10-99人 & 4     & 55    & 42    & 0     & 0     & 0 \\
          & 100-499人 & 0     & 0     & 0     & 2     & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
    \midrule
    支持向量机 &       & \multicolumn{6}{c}{} \\
          & 0人    & 65    & 222   & 0     & 0     & 0     & 0 \\
          & 1-9人  & 31    & 476   & 0     & 0     & 0     & 0 \\
          & 10-99人 & 0     & 70    & 31    & 0     & 0     & 0 \\
          & 100-499人 & 0     & 0     & 1     & 1     & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
    \midrule
    神经网络  &       & \multicolumn{6}{r}{} \\
          & 0人    & 131   & 156   & 0     & 0     & 0     & 0 \\
          & 1-9人  & 84    & 419   & 4     & 0     & 0     & 0 \\
          & 10-99人 & 3     & 64    & 34    & 0     & 0     & 0 \\
          & 100-499人 & 0     & 0     & 0     & 2     & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
    \midrule
    Logistic回归 &       & \multicolumn{6}{c}{} \\
          & 0人    & 104   & 181   & 2     & 0     & 0     & 0 \\
          & 1-9人  & 48    & 453   & 6     & 0     & 0     & 0 \\
          & 10-99人 & 2     & 62    & 37    & 0     & 0     & 0 \\
          & 100-499人 & 0     & 0     & 0     & 2     & 0     & 0 \\
          & 500-999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     & 0     & 0 \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:addlabel}%
\end{table}%



%---------------------------------------
\section{模型评估}
%---------------------------------------
\label{st3}
各个模型的效果采用精确度、召回率、F1-评分、支持度四个指标进行评估。具体结果详见表 3.5。
% Table generated by Excel2LaTeX from sheet 'Sheet5'
\begin{table}[H]
  \centering
  \caption{3类阿片类药物报告量的6种机器学习模型结果}
   \resizebox{0.85\textwidth}{!}{
    \begin{tabular}{cccccccccccccccc}
    \toprule
    \multirow{2}[3]{*}{\textbf{机器学习算法}} & \multirow{2}[3]{*}{\textbf{药物报告量}} & \multicolumn{4}{c}{\textbf{合成阿片类}} &       & \multicolumn{4}{c}{\textbf{非合成阿片类}} &       & \multicolumn{4}{c}{\textbf{半合成阿片类}} \\
\cmidrule{3-6}\cmidrule{8-11}\cmidrule{13-16}          &       & \textbf{精确率} & \textbf{召回率} & \textbf{F1-评分} & \textbf{支持度} &       & \textbf{精确率} & \textbf{召回率} & \textbf{F1-评分} & \textbf{支持度} &       & \textbf{精确率} & \textbf{召回率} & \textbf{F1-评分} & \textbf{支持度} \\
    \midrule
    最近邻法  &       &       &       &       &       &       &       &       &       &       &       &       &       &       &  \\
          & 0人    & 0.31  & 0.36  & 0.33  & 87    &       & 0.46  & 0.53  & 0.49  & 251   &       & 0.3   & 0.4   & 0.34  & 55 \\
          & 1-9人  & 0.5   & 0.52  & 0.51  & 290   &       & 0.74  & 0.65  & 0.69  & 579   &       & 0.52  & 0.53  & 0.52  & 241 \\
          & 10-99人 & 0.75  & 0.69  & 0.72  & 512   &       & 0.4   & 0.6   & 0.48  & 67    &       & 0.74  & 0.67  & 0.7   & 491 \\
          & 100-499人 & 0.45  & 0.52  & 0.48  & 71    &       & 0     & 0     & 0     & 0     &       & 0.58  & 0.59  & 0.59  & 153 \\
          & 500-999人 & 0.5   & 1     & 0.67  & 1     &       & 0     & 0     & 0     & 0     &       & 0.25  & 0.42  & 0.31  & 12 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0.56  & 1     & 0.72  & 9 \\
          & 总体    & 0.61  & 0.6   & 0.6   & 961   &       & 0.64  & 0.61  & 0.62  & 897   &       & 0.62  & 0.61  & 0.61  & 961 \\
    \midrule
    决策树   &       &       &       &       &       &       &       &       &       &       &       &       &       &       &  \\
          & 0人    & 0.41  & 0.41  & 0.41  & 101   &       & 0.48  & 0.45  & 0.47  & 302   &       & 0.23  & 0.23  & 0.23  & 73 \\
          & 1-9人  & 0.47  & 0.48  & 0.47  & 291   &       & 0.59  & 0.62  & 0.61  & 480   &       & 0.49  & 0.48  & 0.48  & 250 \\
          & 10-99人 & 0.66  & 0.66  & 0.66  & 470   &       & 0.47  & 0.42  & 0.44  & 113   &       & 0.66  & 0.67  & 0.66  & 442 \\
          & 100-499人 & 0.52  & 0.46  & 0.49  & 94    &       & 1     & 1     & 1     & 2     &       & 0.63  & 0.6   & 0.62  & 164 \\
          & 500-999人 & 1     & 0.4   & 0.57  & 5     &       & 0     & 0     & 0     & 0     &       & 0.45  & 0.47  & 0.46  & 19 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0.75  & 0.92  & 0.83  & 13 \\
          & 总体    & 0.56  & 0.56  & 0.56  & 961   &       & 0.54  & 0.54  & 0.54  & 897   &       & 0.57  & 0.57  & 0.57  & 961 \\
    \midrule
    随机森林  &       &       &       &       &       &       &       &       &       &       &       &       &       &       &  \\
          & 0人    & 0.32  & 0.49  & 0.39  & 65    &       & 0.49  & 0.52  & 0.51  & 271   &       & 0.26  & 0.32  & 0.28  & 60 \\
          & 1-9人  & 0.57  & 0.52  & 0.54  & 332   &       & 0.73  & 0.66  & 0.69  & 561   &       & 0.54  & 0.54  & 0.54  & 248 \\
          & 10-99人 & 0.73  & 0.7   & 0.72  & 499   &       & 0.44  & 0.7   & 0.54  & 63    &       & 0.75  & 0.68  & 0.72  & 494 \\
          & 100-499人 & 0.52  & 0.7   & 0.6   & 61    &       & 1     & 1     & 1     & 2     &       & 0.58  & 0.67  & 0.62  & 134 \\
          & 500-999人 & 0.5   & 0.25  & 0.33  & 4     &       & 0     & 0     & 0     & 0     &       & 0.2   & 0.33  & 0.25  & 12 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0.81  & 1     & 0.9   & 13 \\
          & 总体    & 0.63  & 0.62  & 0.62  & 961   &       & 0.64  & 0.62  & 0.63  & 897   &       & 0.64  & 0.62  & 0.63  & 961 \\
    \midrule
    支持向量机 &       &       &       &       &       &       &       &       &       &       &       &       &       &       &  \\
          & 0人    & 0     & 0     & 0     & 0     &       & 0.23  & 0.68  & 0.34  & 96    &       & 0     & 0     & 0     & 0 \\
          & 1-9人  & 0.59  & 0.53  & 0.56  & 333   &       & 0.94  & 0.62  & 0.75  & 768   &       & 0.61  & 0.53  & 0.57  & 285 \\
          & 10-99人 & 0.82  & 0.65  & 0.72  & 598   &       & 0.31  & 0.97  & 0.47  & 32    &       & 0.75  & 0.65  & 0.7   & 520 \\
          & 100-499人 & 0.24  & 0.69  & 0.36  & 29    &       & 0.5   & 1     & 0.67  & 1     &       & 0.51  & 0.57  & 0.54  & 141 \\
          & 500-999人 & 0.5   & 1     & 0.67  & 1     &       & 0     & 0     & 0     & 0     &       & 0.05  & 0.33  & 0.09  & 3 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0.69  & 0.92  & 0.79  & 12 \\
          & 总体    & 0.72  & 0.61  & 0.66  & 961   &       & 0.84  & 0.64  & 0.69  & 897   &       & 0.67  & 0.6   & 0.64  & 961 \\
    \midrule
    神经网络  &       &       &       &       &       &       &       &       &       &       &       &       &       &       &  \\
          & 0人    & 0.22  & 0.48  & 0.3   & 46    &       & 0.46  & 0.6   & 0.52  & 218   &       & 0     & 0     & 0     & 7 \\
          & 1-9人  & 0.53  & 0.56  & 0.55  & 284   &       & 0.83  & 0.66  & 0.73  & 639   &       & 0.58  & 0.51  & 0.54  & 281 \\
          & 10-99人 & 0.8   & 0.68  & 0.73  & 560   &       & 0.34  & 0.89  & 0.49  & 38    &       & 0.71  & 0.65  & 0.68  & 492 \\
          & 100-499人 & 0.46  & 0.54  & 0.5   & 71    &       & 1     & 1     & 1     & 2     &       & 0.61  & 0.57  & 0.59  & 166 \\
          & 500-999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0.62  & 0.67  & 0.65  & 15 \\
          & 总体    & 0.67  & 0.62  & 0.64  & 961   &       & 0.72  & 0.65  & 0.67  & 897   &       & 0.65  & 0.59  & 0.62  & 961 \\
    \midrule
    Logistic回归 &       &       &       &       &       &       &       &       &       &       &       &       &       &       &  \\
          & 0人    & 0     & 0     & 0     & 1     &       & 0.36  & 0.68  & 0.47  & 154   &       & 0     & 0     & 0     & 0 \\
          & 1-9人  & 0.57  & 0.56  & 0.57  & 307   &       & 0.89  & 0.65  & 0.75  & 696   &       & 0.37  & 0.53  & 0.43  & 169 \\
          & 10-99人 & 0.84  & 0.65  & 0.73  & 616   &       & 0.37  & 0.82  & 0.51  & 45    &       & 0.86  & 0.59  & 0.7   & 656 \\
          & 100-499人 & 0.29  & 0.69  & 0.41  & 35    &       & 1     & 1     & 1     & 2     &       & 0.43  & 0.55  & 0.48  & 122 \\
          & 500-999人 & 1     & 1     & 1     & 2     &       & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 1 \\
          & 1000-4999人 & 0     & 0     & 0     & 0     &       & 0     & 0     & 0     & 0     &       & 0.75  & 0.92  & 0.83  & 13 \\
          & 总体    & 0.73  & 0.62  & 0.67  & 961   &       & 0.78  & 0.66  & 0.69  & 897   &       & 0.72  & 0.58  & 0.63  & 961 \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:addlabel}%
\end{table}%
可以发现，KNN模型在预测三类阿片类药物的使用量方面的预测性能都一般。决策树模型在预测三类阿片类药物的使用量方面的预测性能都一般。随机森林模型在预测三类阿片类药物的使用量方面的预测性能都一般。支持向量机模型在预测半合成阿片类药物的结果上一般，在预测合成阿片类药物的结果上良好，在预测非合成阿片类药物的结果上较优。神经网络模型在预测合成阿片类药物和半合成阿片类药物的结果上一般，在预测非合成阿片类药物的结果上良好。Logistic模型在预测三类阿片类药物的结果上都表现良好。

通过上述四个指标进行具体的模型效果评价之后，并用10折交叉验证法作为参考对模型效果进行进一步评估，为了便于观察对数据结果绘制箱式图，结果如图 3.5 所示。
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.85\textwidth]{bodyfigures/All_Box.jpg}
\end{center}
\caption{6种机器学习算法的K折验证结果箱式图}
\label{q2}
\end{figure}
对于合成阿片类药物的预测模型而言，支持向量机模型的预测精确度从均值和变异程度而言效果最佳，其次是逻辑模型，虽然在精确度均值上神经网络模型略微由于逻辑回归模型，但是总体的变异而言逻辑回归表现更好。由于决策树模型在过拟合和欠拟合问题上的不稳定性，其预测效果表现最差，而集成了多个决策树基模型的随机森林模型的预测精确度明显优于决策树。K 近邻算法作为最简单的机器学习模型，预测效果表现也算中规中矩，优于决策树和随机森林但是劣于人工神经网络。

对于半合成阿片类药物的预测模型而言，支持向量机模型的预测精确度无论是从均值和变异程度而言效果依然表现最佳，且变异程度相比于合成类更低。其次是逻辑模型和神经网络模型。决策树、随机森林、K近邻模型相比于合成类的变异程度明显大幅度增大。说明模型预测效果并不稳定。

对于非合成阿片类药物的预测模型而言，仍然是支持向量机模型的预测精确度综合表现最佳，逻辑回归、神经网络的表现次之。而6 种模型的变异程度相对于另外两类阿片类药物都明显更低，说明各个模型对于非合成类药物的预测效果最具有稳定性，预测结果最可靠。

综上而言， K近邻法、决策树、随机森林这三个机器学习模型在于传统逻辑回归模型对比不占明显优势。因此本文以10 折交叉验证方法为评估指标得出最优的模型为支持向量机模型，其次为逻辑回归和神经网络模型，最差为决策树模型。
%---------------------------------------
\chapter{结论}
%---------------------------------------
支持向量机模型和人工神经网络模型在预测效果中的性能都比较理想。支持向量机模型的精确度$>0.8$，而人工神经网络模型的精确度$>0.7$。 对比与传统的预测模型而言，支持向量机和神经网络模型容易调整参数，能够生成预测效能更好的模型。

对于决策树和随机森林模型，由于随机森林模型本质上是在以决策树为基学习器构建Bagging集成的基础上，进一步决策树训练过程中引入了随机属性选择。所以本文也证实其理论性，发现随机森林模型的预测效能要明显优于决策树模型。随机森林模型能够集成多颗决策树进行预测，客服了单颗决策树泛化能力不足的缺点，有助于模型的外推。同时，集成学习模型也容易调整参数，可以生成预测效能更好的模型，为类似研究提供新思路和方法。KNN模型作为最简单的机器学习模型之一，在方法思路上具有简洁的优点，但是其实现过程所需计算机空间内存较大，且本文的实证研究发现其预测效能一般。但是相比于传统的统计预测模型而言，容易调整参数和思路简洁是一个明显的优势。传统的logistics回归在本实证研究中的预测效能表现虽然不是最佳，但是明显优于决策树和随机森林等模型。但是传统的logistics 模型的多重共线性和变量间相互关系作用的缺点。

本文从各类阿片类药物使用情况的研究背景出发，分析了不同年份和不同地区阿片类药物报告量的现状，在公共卫生事业越来越重要的情况下，成瘾性药物的研究更应该引起学者们的注意。对阿片类药物使用情况的预测不仅可以让卫生管理人员直观看到社会情况，还可以帮助相关政府部门制定必要的卫生政策。本研究主要工作如下：不同地区阿片类药物报告量、相关社会经济指标数据的采集和清洗；利用数据可视化对阿片类药物报告量的描述性统计分析；相关社会经济指标数据的特征选择；不同类型的阿片类药物报告量的机器学习建模。总结来说，本文能将多种机器学习算法运用到阿片类药物报告量的预测中，更具机器学习模型在阿片类药物报告量数据上的表现，做到分类处理的精准预测。

虽然本文对不同类的阿片类药物报告量预测做到了不错的效果，但是本文的工作还有很多的不足之处，其中包括以下几个方面：虽然收集到2017年阿片类药物的报告量，但并没有收集到当年分的社会经济指标数据，导致大量数据失效；且在数据清洗过程中清洗掉大量数据，最终使用到的有效数据只有9000多条，相对于机器学习模型而言数据量偏少；社会经济指标未能构造多维，本文可以通过已有变量构造其他变量；使用的算法模型不够新。本文使用到的机器学习算法都是比较传统的机器学习算法，这些算法在一定程度上还有可以优化的空间。比如梯度提升回归树算法、CART决策树和C4.5决策树算法。
%---------------------------------------



